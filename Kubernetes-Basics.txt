Container Orchestration:
------------------------
-- Process of automatically deploying and managing containers
-- Technologies --> Docker swarm, Mesos, Kubernetes


Running Image --> Container --> Application
Container is deployed on Physical Server/Virtual Machine/Cloud Instance --> Machine --> NODE



Kubernetes Architecture (Cluster --> Group of nodes):
-----------------------------------------------------
-- node --> machine --> worker --> minions --> contains the application 
                                               (enclosed in containers)

-- cluster --> collection of nodes --> sharing load

-- master node/control plane --> Kubernetes installed 
                             --> watches the nodes 
                             --> responsible for managing containers on worker nodes


         Single cluster --> 5000 nodes theoretically
                        --> 100 to 500 nodes recommended practically.

         Single node    --> Approx. 256 IP addresses to be assigned to pods on one node
                            110 pods are allowed to be created on one node.
                           
			    110 pods with version 1 (old) of your app --> UP
                            110 pods with version 2 (new) of your app --> Bring up these pods
                            ---------------------------
                            220 pods are up and running

                            
			    110 pods with version 1 (old) of your app --> Bring down these pods
                            110 pods with version 2 (new) of your app --> UP
                            ---------
                            110 pods are up and running


Online Shopping Application: Microservice based architecture
-------------------------------------------------------------
1. Product Catalog    -- Microservice 1 --> JAVA      
                                        --> 
                         Microservice 1a --> Container1 
                         Microservice 1b --> Container5  --> POD 2 --> 50M users
			                                    (Scale it --> 50 Copies)					

2. Order Management   -- Microservice 2 --> Python    
                                        --> Container 2  --> POD 1 --> 25M users
						             (Scale it --> 25 Copies)


3. Payment Management -- Microservice 3 --> Python    
                                        --> Container 3  --> POD 3 --> 10M users


4. Shipment Management-- Microservice 4 --> JAVA      
                                        --> Container 4 --> POD 4 --> 10M users



Components-->
------------
Master Node:
------------
1. API Server --> Front end --> used to interact with cluster 
                            --> only component that connects to etcd 
                  Like a gatekeeper --> checks authentication, authorization, etc.

2. etcd keystore --> distributed, reliable key store used to store data for managing clusters 
                 --> ensure no conflict between the masters
		 --> stores details about existing nodes, containers & where are they running
                 --> Like a watcher
                 --> Features: fully replicated, highly available, consistent, reliable,               
                               simple, secure, fast

3. scheduler --> distributing the load across multiple containers 
             --> assigns newly created containers/PODS to nodes                                                                 

4. controllers --> noticing and responding when nodes or containers go down 
               --> bring up new containers

Worker Node:
------------

5. container runtime --> software to run containers --> docker, rkt, cri-o , etc

6. kubelet --> agent that runs on each node --> to make sure containers are running 
           --> understands YAML

7. Kube-proxy --> manages network rules on each node


Master Node --> kube-apiserver
		etcd 
		controller manager
		scheduler

Worker Node --> kubelet agent --> interact with master node to provide health information 
                                  about worker node
		container runtime --> Docker / containerd


CLI utility -->
kubectl --> kube control tool --> to deploy and manage applications on cluster

kubectl run --> Pods --> containers --> deploy application 

kubectl cluster-info --> to get cluster information

kubectl get nodes --> list of all node in cluster


Pods --> containers are encapsulated into k8s object called pods
-- single instance of an application/microservice
-- smallest object of k8s
-- single instance of application running on node --> pod
-- 1:1 relationship with containers
-- 1:N relationship with containers (helper containers)


Docker 
------
Image --> Read only --> Application + Dependencies 
Run image --> Container --> Read-write 

# docker run -d --name cont1 centos:8  --> Cont1
# docker run -d --name cont2 ubuntu:18.04  --> Cont2

docker-compose.yaml
services:
  cont1:
    image: centos:8
  cont2:
    image: ubuntu:18.04



docker run -d --name nginx_webserver nginx  --> creating a container
kubectl run nginx_webserver --image=nginx --> creating a pod


docker ps        --> running containers in docker
kubectl get pods --> running pods in k8s cluster 

kubectl get pods -o wide --> 
additional information about internal IP of pod and node on which pod is running


docker inspect  --> more information about volume/network/containers
kubectl describe pod nginx_webserver --> get more information about the pod


YAML
----
1. Key-Value pair
Fruit: Apple
<Key1>: <value1>
Fruit: Mango
<Key1>: <value2>
Vegetable: Capsicum
<Key2>: <value1>

2. Array/Lists --> ordered --> One key with many values
Fruits: --> Key
- Apple   --> <value1>
- Banana  --> <value2>
- Mango   --> <value3>


3. Dictionary/Maps --> unordered
Apple:  --> <Key>
    Calories: 170  --> <key:Value>
    Carbs: 25g    --> <key:Value>
Banana:  --> <Key>
    Calories: 120
    Carbs: 45g


Kubernetes objects:
-------------------
-- persistent entities in kubernetes
-- used to represent the state of the cluster

Kubernetes objects include:

1. Pod (smallest unit)  --> Encapsulates container(s) --> Containers represents application/microservice
					(Run Image)			       (Image created by developer)

2. ReplicaSet  --> Allows creation of multiple pods with same spec --> High availability, Scalability

3. Deployment  --> Allows to maintain different versions of application by launching multiple ReplicaSets
	       --> High Availability, Scalability
 		
4. Namespace   --> Logical division of the system space --: Like HDD is partitioned 

5. DaemonSet   --> Similar to ReplicaSet --> Run one pod on every worker node --: Used for Log collection

6. Service

7. ConfigMap

8. Secrets	

# kubectl get nodes --> no. of nodes in cluster
# kubectl version --> k8s version
# cat /etc/os-release --> OS version


1. PODS:
- Each container in k8s is encapsulated in object called pod
       - What is encapsulated? --> container, storage, resource, ip address, options.
       - Smallest unit of deployment

Creating Pods:
a. Imperative way  --> command
b. Declarative way --> YAML



Creating pods:
a. Imperative way:
# kubectl get pods 
--> no. of pods that exists on the system

# kubectl get pods 
-> total no. of ready(running)/ total no. of containers part of this pod --> READY column

# kubectl get pods -o wide 
--> get the node on which pod is placed and Ip address of pod

# kubectl run nginx-pod --image=docker.io/library/nginx:run
--> create a pod with nginx image

# kubectl describe pod nginx-pod 
--> look at pod details to identify the image used to create pod. Also, displays the node on which pod is placed

# kubectl delete pod nginx-pod 
--> delete a pod



States of pods
--------------
1. pending state
Scheduler can not a worker node to place

2. waiting state
Pod is assigned to the node. but pod is not created.
eg: image is not available for pod creation

3. running state
When all containers in the pod is up and running


b. Declarative way (Pods with YAML):

Root properties must be present:

apiVersion --> depending on what you want to create
kind --> Pod, Service, ReplicaSet, Deployment
metadata --> data about the object 
spec --> additional information about object to be created

Eg1: pod_with_one_container.yaml

apiVersion: v1
kind: Pod
metadata:
  name: pod1
spec:
  containers:
  - name: my-container
    image: docker.io/nginx:run
    ports:
    - containerPort: 80


# kubectl create -f yamlfilename
create --> create the setup as mentioned in the yaml file only for the first time

# kubectl apply -f yamlfilename
apply --> Check whether any pods are running with spec mentioned, if yes, map it to the name. If not, create new pod with spec

# kubectl create -f pod_with_one_container.yaml
   
# kubectl get pods


Eg2: pod_with_two_containers.yaml
apiVersion: v1
kind: Pod
metadata:
  name: twocontainers-pod
  labels:
    owner: Jill
    tier: frontend
    app: webapp
spec:
  containers:
  - name: simpleservice
    image: registry.example.com:5000/docker.io/mhausenblas/simpleservice:0.5.0
    ports:
    - containerPort: 9876
  - name: shell
    image: registry.example.com:5000/centos:7
    command:
      - "bin/bash"
      - "-c"
      - "sleep 10000"

# curl <Pod_IP>:9876/info --> To view the application created using simple service image.


# kubectl exec -it twocontainers -- bash
It enables the user to enter the container running in a pod

# kubectl exec -it twocontainers -c shell -- bash
It enables the user to enter the conatiner named "shell" running in the pod 


IDEs --> to create yaml files --> PyCharm, IntelliJ, Atom, NetBeans, Eclipse, etc. 

HANDSON:
-------
Create a new pod with the name redis and image redis123 using yaml --> pod-definition.yaml
apiVersion: v1 
kind: Pod 
metadata:  
  name: myapp-pod 
  labels:  
    app: myapp 
    type: back-end 
spec: 
  containers: 
    - name: redis
      image: redis123


# kubectl run redis --image=redis123 -o yaml > redis.yaml --> automatically creates yaml file

# kubectl apply -f redis.yaml --> edit and update pods

--------------------------------------------------------------------------------------------------

2. LABELS and SELECTORS:

- Labels are used to organize the objects like pods
# kubectl get pods --show-labels

- Labelling can be done at the time of creation of pod  --> In metadata section of yaml file
Eg:
apiVersion: v1
kind: Pod
metadata:
  name: new-pod
  labels:
    tier: frontend
    app: webapp
spec:
  containers:
  - name: my-container
    image: docker.io/nginx:alpine
    ports:
    - containerPort: 80


- After creation also, label can be added or deleted
	# kubectl label pod <podname> key=value
       Eg: # kubectl label pod new-pod owner=John app=testapp

       Eg: # kubectl label pod new-pod owner-

- Selectors are used to select subset of objects

Types:
a. Equality-based selectors (=, ==, !=)
Ex: # kubectl get pods --selector app=myapp
    # kubectl get pods -l app=myapp


b. Set-based selectors (in, notin, exists)
# kubectl get pods --selector 'type in (front-end,back-end)'
# kubectl get pods --selector 'type notin (front-end,back-end)'
# kubectl get pods --selector type

Task: 
Create 2 pods using nginx image.
pod1 labels - owner: <your_name>, team: developers, app: devapp
pod2 labels - owner: sysadmin, team: admins, app: opsapp

pod names --> mypod and adminpod
container names - container1, container2

Verify using equality where team is developers 
Verify using set selectors where team is either developers or admins
=====================================================================
Ex: exercise.yaml

apiVersion: v1
kind: Pod
metadata:
  name: mypod
  labels:
    owner: vidyadhara
    team: developers
    app: devapp
spec:
  containers:
  - name: container1
    image: docker.io/library/nginx:run
    ports:
    - containerPort: 80

3. REPLICASET:
- Ensures the stable set of replica pods running at any given time
- monitor the pods and if any of them fail, deploy new ones
- as hundreds of pods may be running different applications, labelling can be used to differentiate or identify them.

Advantages:
- Provides high availability
- Load balancing & scaling

Eg: replica-set.yaml

apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: my-replica-set
spec:
  replicas: 5
  selector:
    matchLabels:
     app: frontend
  template:
    metadata:
      name: replica-pod
      labels:
        app: frontend
    spec:
      containers:
      - name: replica-container
        image: docker.io/nginx:run
       


     
# kubectl create -f replica-set.yaml
# kubectl get replicaset
# kubectl get pods
# kubectl delete pods <pod_name>
# kubectl get pods

- Try to delete a pod --> new pod will be created with different name to maintain desired number of replicas 

# kubectl describe replicaset myapp-rs --> to get details and history of events related to replica set


kubectl replace -f rs.yml ==> when u need to update

kubectl scale --replicas=6 -f rs.yaml  --> using yaml file name
OR
kubectl scale rs myapp-rc --replicas=6  --> using replicaset name

Horizontal pod autoscaler (HPA) --> autoscaling
define the resources

---------------------------------------------------------------------------------------------------

4. DEPLOYMENT:
--------------
Eg--> deployment-example.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      name: nginx-pod
      labels:
       app: nginx
    spec:
      containers:
      - name: nginx-cont
        #image: docker.io/nginx:run    --> representing version 1 of your app

        image: docker.io/nginx:alpine    --> representing version 2 of your app

      
# kubectl create -f deployment-example.yaml
# kubectl get deployments
# kubectl get rs
# kubectl get pods
# kubectl get all

	
Rollouts and Versioning:
-----------------------
- When we create a deployment, it triggers a rollout
- new roll out creates new deployment revision
- Whenever container version is updated, a new rollout is triggered and a new deployment revision is created 
- Helps to keep track and roll back to previous version

# kubectl rollout status deployment/nginx-deployment

# kubectl rollout history deployment/nginx-deployment


Deployment Strategies:
1. Recreate strategy: To upgrade, delete all the replicas of the application instances and create new ones
- Suffers from application downtime
- Not default deployment strategy

2. Rolling update strategy: Bring up newer version and take down older version one by one
- Application never goes down 
- Default deployment strategy

Updates:
- May be updating the container, container port, updating labels, etc.
- To make any of the changes:
1. update through deployment definition file
# kubectl apply -f deployment-example.yaml  --> when file is known
# kubectl edit deployment nginx-deployment --record=true --> when file is not known, use name of the deployment

2. update through command --> does not change the file 
# kubectl set image deployment/nginx-deployment nginx-cont=docker.io/nginx:run
-- Check the status and history
# kubectl rollout status deployment/nginx-deployment
# kubectl rollout history deployment/nginx-deployment

Upgrades:
- When a new deployment is created, it first creates a replicaset automatically which in turn creates the pods
- When you upgrade the application, the deployment object creates new replica set and pods.
- At the same time, it takes down the pods in old replica set using rolling update strategy
# kubectl get replicasets

- To roll back to previous revision --> destroy the pods in new replica set and bring older ones up
# kubectl rollout undo deployment/nginx-deployment
# kubectl rollout undo --to-revision=3 deployment/nginx-deployment

Annotations:
------------
- Provide brief description of why a specific revision was created.
Eg:
 metadata:
   annotations:
     kubernetes.io/change-cause: First rollout

- Add environment tags

----------------------------------------------------------------------------------------------------------------------------------


Networking:
----------
- In docker, IP address is assigned to a container
- In kubernetes, IP address is assigned to a pod

- Each pod gets its own internal IP 
- To do so, we create an internal private network with IP address and all pods are attached to it.
- When multiple pods are deployed, all get separate IP address from this network

Cluster networking:
- k8s does not set up networking for the nodes in the cluster
- We need to set up networking to meet certain requirements:
a. All containers/pods can communicate to one another without NAT
b. All nodes can communicate with all containers/pods and vice-versa without NAT

- To set up networking, we can use existing solutions such as -
  cisco ACI networks, cilium, big cloud fabric, flannel, VMWare NSX and calico

5. SERVICES:
------------
- Enables communication between various components within and outside the application

Eg:
Pod1 --> Frontend --> nginx
Pod2 --> Backend
Pod3 --> External data source

- From node, we can access the pod webpage using curl command or browser:
# curl http://10.244.0.2

- From outside, we need to access the pod through the node --> Use k8s service

Service Types:
-------------
1. NodePort: 
- Listens to a port on the node and forwards the request to the pod running on the node.
- To access internal pod accessible on a port on the node

- Port on pod --> target port --> actual application is running is here
- Port on the service --> port --> service has its own IP address --> Cluster IP of the service
- Port on the node --> node port --> used to access server externally --> Range 30000 to 32767


Ex: 
Step 1: Create a service --> simple-service.yaml
apiVersion: v1
kind: Service
metadata:
   name: myapp-service
spec:
   type: NodePort
   ports:
    - targetPort: 80
      port: 80
      nodePort: 30008
   selector:  
      app: myapp
       
selector:  --> provide a list of labels to identify and link pods to service 
--> all pods with matching label will be selected 
--> load randomly balanced

# kubectl create -f simple-service.yaml
# kubectl get svc


Step 2: Create a pod with same label as mentioned in selector field of the service --> simple-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: service-pod
  labels:
    app: myapp
spec:
  containers:
  - name: web-server1
    image: docker.io/nginx:run

# kubectl create -f simple-pod.yaml
# kubectl get pods -o wide --> Check the IP of the node on which the pod is running
# curl http://<node_IP>:30008


- Mandatory field in the ports section --> only port
- If we don't provide target port, it is assumed to be same as port
- If we don't provide nodePort, any free port in the valid range is assigned automatically


2. ClusterIP:
- Creates virtual IP inside the cluster to enable communication between different servers

Eg:
Set of pods --> Frontend  --> Web Server
         |
         |
k8s service to group backend pods --> ClusterIP
	 |
	 |
Set of pods --> Backend --> 
	 |
         |
k8s service to group Redis pods  --> ClusterIP
	 |
	 |
Set of pods --> Redis

Ex: Create a service --> service-definition.yaml
apiVersion: v1
kind: Service
metadata:
   name: back-end
spec:
   type: ClusterIP
   ports:
    - targetPort: 80
      port: 80
   selector: 
      app: myapp
      type: back-end  

# kubectl create -f service-definition.yaml
# kubectl get svc

- Service can be accessed by pods using service name or cluster IP.


3. Load Balancer: 
- Load distribution across different web servers
- Only works with supported cloud platforms like GCP, Azure, AWS

HANDSON:
--------
# kubectl get service
# kubectl describe service <service-name>

Endpoint: Service identified based on the label and selector of the pods

--------------------------------------------------------------------------------------------------------------------


6. NAMESPACES:
--------------
- provide a scope for Kubernetes object names
- isolate the pods or other objects into one environment


# kubectl get ns 
- default ==> used normally if we don't mention NS explicitly
- kube-system ==> non-modifiable ns, contains the master node components

#  kubectl get all -n kube-system

Methods:
1. DECLARATIVE
Step 1 : Create namespace
Eg: namespace-create.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: dev-namespace

# kubectl create -f namespace-create.yaml
# kubectl describe ns dev-namespace

Step 2: Create pods in the namespace:
Specify the namespace in metadata field in yaml file  
apiVersion: v1
kind: Pod
metadata:
  name: first-dev-pod
  namespace: dev-namespace
spec:
  containers:
  - name: web-server1
    image: docker.io/nginx:alpine
# kubectl create -f <yamlfile> 
# kubectl get pods -n dev-namespace
-----------------------------------------------------------------------------------

2. IMPERATIVE
Step 1 : Create namespace
# kubectl create namespace prod-namespace
# kubectl describe ns prod-namespace

Step 2: Create pods in the namespace
Specify the namespace while creating the environment 
# kubectl run first-prod-pod --image=docker.io/nginx:alpine -n <nameofns>


Make any namespace as default: 
# kubectl config set-context --current --namespace <namespace>
----------------------------------------------------------------------------------------------------
------------------------------

7. DAEMONSETS:
-------------
- Ensures that all nodes run a copy of a pod --> one copy each on every worker node
- Replica field is not used

- It can be for resource utilization, log collections
--> collecting logs - Create pod with the fluentd image
Ex
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: myapp-ds
  
spec:
  selector:
    matchLabels:
      app: myapp-agent
      
  template:
    metadata:
      name: myapp-pod
      labels:
        app: myapp-agent
        agent: log-collect
    spec:
      containers:
      - name: myapp-log-cont
        image: docker.io/nginx:alpine



# kubectl create -f daemonset.yaml
# kubectl get ds
# kubectl delete ds <name_of_ds>













-------------------------------------------------------------------------------------------------------------------------------
8. CONFIGMAPS: 
--------------

- used to store non-confidential data in key-value pairs and allow other objects (Pod) to use.
- Pods can consume ConfigMaps in the below 3 methods. 

	1. As an environment variables
	2. Command-line arguments
	3. Configuration files in a volume















Step 1: Create configuration map --> configmap-example.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: mysql-config
data:
  db_name: mydb
  port: "3308"
  max_allowed_packet: "512M"

# kubectl create -f configmap-example.yaml
# kubectl get cm

Step 2: Create pod --> configmap-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: miysql-pod
  labels:
    app: backend
    environment: prod
spec:
  containers:
  - name: mysql-cont
    image: docker.io/nginx:run
    ports:
    - containerPort: 80
    envFrom:
    - configMapRef:
        name: mysql-config

# kubectl create -f configmap-pod.yaml
# kubectl get pods

- Enter the pod shell and check the environment variables
# kubectl exec mysql-prod -it -- sh
  env  --> use this command inside shell


---------------------------------------------------------------------------------------------------------------------------------
9. SECRETS:
-----------
- to store the confidential information 

- Create two files for storing username and password
 echo -n 'db_username=app_admin' > db_username.txt
 echo -n 'db_password=Infy@123+' > db_password.txt








- For more security, encode using base64
echo -n 'app_admin' | base64
YXBwX2FkbWlu
echo -n 'Infy@123+' | base64
SW5meUAxMjMr

- To decode, use--
echo -n 'YXBwX2FkbWlu' | base64 --decode
echo -n 'SW5meUAxMjMr' | base64 --decode


Step 1: Create secret
# kubectl create secret generic my-db-secret --from-file=username.txt --from-file=password.txt

# kubectl get secrets
# kubectl describe secret my-db-secret


Step 2: Create pod --> secret-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: secret-pod
spec:
  containers:
  - name: nginx
    image: docker.io/nginx:run
    volumeMounts:
    - name: "my-secret"
      mountPath: "/root/my-volume"
      readOnly: true
  volumes:
  - name: "my-secret"
    secret:
      secretName: my-db-secret

# kubectl apply -f secret-pod.yaml
# kubectl get pods
# kubectl exec secret-pod -it -- sh

- Check the files in /root/my-volume
-----------------------------------------------------------------------------------------------------------------------------------




